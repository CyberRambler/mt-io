{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kS_mq4yAlXHZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.3\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Bidirectional, GRU\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IWgBGmaplzcp"
      },
      "outputs": [],
      "source": [
        "def get_model(image_channels=3, vgg_weights_path=None):\n",
        "    image_shape = (500, 500, image_channels)  # 大小不定\n",
        "    base_model = VGG16(weights=None, include_top=False, input_shape=image_shape)\n",
        "    if vgg_weights_path is not None:  # 基础模型预训练微调\n",
        "        base_model.load_weights(vgg_weights_path)\n",
        "        base_model.trainable = True\n",
        "    else:\n",
        "        base_model.trainable = False\n",
        "\n",
        "    # 基础模型输入和输出\n",
        "    input = base_model.input\n",
        "    sub_output = base_model.get_layer('block5_conv3').output\n",
        "\n",
        "    # tf.print(sub_output.shape)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', name='rpn_conv1')(sub_output)\n",
        "    # x1 = Lambda(_reshape, output_shape=(None, 512))(x)  # output_shape not include batch dim, (N*H, W, C), C=512\n",
        "    # b = tf.shape(x)\n",
        "    # x1 = tf.reshape(x, [b[0] * b[1], b[2], b[3]])  # (N x H, W, C)\n",
        "    x1 = tf.squeeze(x, axis=0)\n",
        "    # x1.set_shape((None, None, 512))\n",
        "    # x1 = tf.ensure_shape(x1, (31, 31, 512))\n",
        "\n",
        "    x2 = Bidirectional(GRU(128, return_sequences=True, reset_after=False), name='blstm')(x1)\n",
        "    b = tf.shape(x)\n",
        "    x3 = tf.reshape(x2, [b[0], b[1], b[2], 256])  # (N, H, W, 256)\n",
        "    x3 = Conv2D(512, (1, 1), padding='same', activation='relu', name='lstm_fc')(x3)\n",
        "\n",
        "    # 分类分支\n",
        "    cls = Conv2D(10 * 2, (1, 1), padding='same', activation='linear', name='rpn_class_origin')(x3)\n",
        "    # cls = Lambda(_reshape3, output_shape=(None, 2), name='rpn_class')(cls)  # (N, H*W*10, 2)\n",
        "    b = tf.shape(cls)\n",
        "    cls = tf.reshape(cls, [b[0], b[1] * b[2] * 10, 2], name='rpn_class')  # (N, H x W x 10, 2)\n",
        "    # cls_prod = Activation('softmax', name='rpn_cls_softmax')(cls)\n",
        "\n",
        "    # 高度回归分支\n",
        "    regr = Conv2D(10 * 2, (1, 1), padding='same', activation='linear', name='rpn_regress_origin')(x3)\n",
        "    # regr = Lambda(_reshape3, output_shape=(None, 2), name='rpn_regress')(regr)  # (N, H*W*10, 2)\n",
        "    b = tf.shape(regr)\n",
        "    regr = tf.reshape(regr, [b[0], b[1] * b[2] * 10, 2], name='rpn_regress')  # (N, H x W x 10, 2)\n",
        "\n",
        "    # predict_model = Model(input, [cls, regr, cls_prod])\n",
        "\n",
        "    train_model = Model(input, [cls, regr])\n",
        "\n",
        "    return train_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 500, 500, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 500, 500, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 500, 500, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 250, 250, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 250, 250, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 250, 250, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 125, 125, 128 0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 125, 125, 256 295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 125, 125, 256 590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 125, 125, 256 590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 62, 62, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 62, 62, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 62, 62, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 62, 62, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 31, 31, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 31, 31, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 31, 31, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 31, 31, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "rpn_conv1 (Conv2D)              (None, 31, 31, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLambd (31, 31, 512)        0           rpn_conv1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.shape (TFOpLambda) (4,)                 0           rpn_conv1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "blstm (Bidirectional)           (31, 31, 256)        492288      tf.compat.v1.squeeze[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape (TFOpLambda)         (None, None, None, 2 0           blstm[0][0]                      \n",
            "                                                                 tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem_1[0][0] \n",
            "                                                                 tf.__operators__.getitem_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "lstm_fc (Conv2D)                (None, None, None, 5 131584      tf.reshape[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "rpn_class_origin (Conv2D)       (None, None, None, 2 10260       lstm_fc[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "rpn_regress_origin (Conv2D)     (None, None, None, 2 10260       lstm_fc[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.shape_1 (TFOpLambd (4,)                 0           rpn_class_origin[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.shape_2 (TFOpLambd (4,)                 0           rpn_regress_origin[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply (TFOpLambda)   ()                   0           tf.__operators__.getitem_4[0][0] \n",
            "                                                                 tf.__operators__.getitem_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_2 (TFOpLambda) ()                   0           tf.__operators__.getitem_7[0][0] \n",
            "                                                                 tf.__operators__.getitem_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_1 (TFOpLambda) ()                   0           tf.math.multiply[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.multiply_3 (TFOpLambda) ()                   0           tf.math.multiply_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape_1 (TFOpLambda)       (None, None, 2)      0           rpn_class_origin[0][0]           \n",
            "                                                                 tf.__operators__.getitem_3[0][0] \n",
            "                                                                 tf.math.multiply_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape_2 (TFOpLambda)       (None, None, 2)      0           rpn_regress_origin[0][0]         \n",
            "                                                                 tf.__operators__.getitem_6[0][0] \n",
            "                                                                 tf.math.multiply_3[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 17,718,888\n",
            "Trainable params: 3,004,200\n",
            "Non-trainable params: 14,714,688\n",
            "__________________________________________________________________________________________________\n",
            "[<tf.Tensor: shape=(1, 9610, 2), dtype=float32, numpy=\n",
            "array([[[-1.3351656e-03,  1.3548532e-05],\n",
            "        [-1.4091190e-03, -1.0353574e-03],\n",
            "        [ 8.7800773e-04,  1.1358218e-04],\n",
            "        ...,\n",
            "        [-8.7210903e-04, -5.4835749e-04],\n",
            "        [-1.5672736e-04, -6.1123597e-04],\n",
            "        [-2.1770553e-04,  2.3773237e-04]]], dtype=float32)>, <tf.Tensor: shape=(1, 9610, 2), dtype=float32, numpy=\n",
            "array([[[ 1.34330985e-05, -1.75422261e-04],\n",
            "        [ 1.53327524e-03, -5.91784483e-04],\n",
            "        [ 5.31781698e-05,  1.21482729e-03],\n",
            "        ...,\n",
            "        [ 1.89478579e-03, -2.02667620e-03],\n",
            "        [-1.38838263e-03, -3.74453724e-04],\n",
            "        [ 7.75369117e-05,  4.90626204e-04]]], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "input_image = tf.random.normal(shape=(1, 500, 500, 3), dtype=tf.float32)\n",
        "\n",
        "print(model(input_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWROBI4iv9fY"
      },
      "source": [
        "## Convert the Keras model to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2fXStjR4mzkR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\hlp-ai\\AppData\\Local\\Temp\\tmp8eb1bnkn\\assets\n"
          ]
        }
      ],
      "source": [
        "# Convert Keras model to TF Lite format.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TF Lite model as file\n",
        "f = open('ctpn.tflite', \"wb\")\n",
        "f.write(tflite_model)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q_Z5yLxrwbpI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF Lite model: d:\\kidden\\github\\tf\\examples\\lite\\examples\\digit_classifier\\ml\\ctpn.tflite\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "model_path = os.path.join(os.getcwd(), 'ctpn.tflite')\n",
        "print('TF Lite model:', model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TvDxaYU2ui7"
      },
      "source": [
        "## Verify the TensorFlow Lite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xPtbtEJ2uacB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'input_1', 'index': 0, 'shape': array([  1, 500, 500,   3]), 'shape_signature': array([ -1, 500, 500,   3]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[[-1.33516663e-03  1.35493465e-05]\n",
            " [-1.40912004e-03 -1.03535759e-03]\n",
            " [ 8.78007326e-04  1.13583461e-04]\n",
            " ...\n",
            " [-8.72108561e-04 -5.48358657e-04]\n",
            " [-1.56726775e-04 -6.11235853e-04]\n",
            " [-2.17705558e-04  2.37731409e-04]]\n"
          ]
        }
      ],
      "source": [
        "# Run inference with TensorFlow Lite\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "interpreter.resize_tensor_input(input_details[0]['index'], (1, 500, 500, 3), strict=True)\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[0][\"index\"], input_image)\n",
        "\n",
        "print(input_details)\n",
        "\n",
        "interpreter.invoke()\n",
        "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])()[0]\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mnist_tflite.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
